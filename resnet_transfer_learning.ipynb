{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, log_loss, accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_world_assumption(img):\n",
    "    # Calculate the average color of the entire image\n",
    "    mean_color = img.mean(dim=[1, 2])\n",
    "    # Calculate the correction factors for each channel\n",
    "    correction_factors = torch.tensor([0.5, 0.5, 0.5]) / mean_color\n",
    "    # Apply the correction to the image\n",
    "    corrected_img = correction_factors.view(3, 1, 1) * img\n",
    "    #corrected_img = img - mean_color.view(3,1,1) + 0.5\n",
    "    return corrected_img\n",
    "\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((280,280)),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((230,230)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = \"./cell_images\"\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "all_dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=64, shuffle=True) for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Parasitized': 0, 'Uninfected': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Parasitized': 0, 'Uninfected': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets['val'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/racmukk/anaconda3/envs/datasci_env/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/racmukk/anaconda3/envs/datasci_env/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Conv2d(3, 3, kernel_size=7, padding='same'),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(2,2),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(112*112*3, 2))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomCNN(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(7, 7), stride=(1, 1), padding=same)\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): ReLU()\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=37632, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_classes = 2\n",
    "# model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = CustomCNN()\n",
    "model.to('mps') #pytorch metal for M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.Adam(model.fc.parameters(), lr=0.001) #change LR\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #change LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Epoch 1/1\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 343/343 [00:50<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7131 Acc: 0.6292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:08<00:00, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6622 Acc: 0.6139\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "device = 'mps'\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print('-' * 30)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print('-' * 30)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "            dataloader = all_dataloaders['train']\n",
    "        else:\n",
    "            model.eval()\n",
    "            dataloader = all_dataloaders['val']\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "                \n",
    "        # Iterate over data\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Backward pass and optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        epoch_acc = running_corrects / len(dataloader.dataset)\n",
    "\n",
    "        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "./cell_images\n",
    "    train\n",
    "        Uninfected\n",
    "        Parasitized\n",
    "    val\n",
    "        Uninfected\n",
    "        Parasitized\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uninfected_data = [os.path.join('./cell_images/Uninfected', x) for x in os.listdir('./cell_images/Uninfected')]\n",
    "# parasitized_data = [os.path.join('./cell_images/Parasitized', x) for x in os.listdir('./cell_images/Parasitized')]\n",
    "\n",
    "# try:\n",
    "#     os.mkdir('./cell_images/train')\n",
    "#     os.mkdir('./cell_images/val')\n",
    "#     os.mkdir('./cell_images/train/Uninfected')\n",
    "#     os.mkdir('./cell_images/train/Parasitized')\n",
    "#     os.mkdir('./cell_images/val/Uninfected')\n",
    "#     os.mkdir('./cell_images/val/Parasitized')\n",
    "# except Exception: \n",
    "#     pass\n",
    "\n",
    "# train_fraction = 0.8\n",
    "# val_fraction = 0.2\n",
    "\n",
    "# all_data = {'Uninfected':uninfected_data, 'Parasitized':parasitized_data}\n",
    "# for key in all_data:\n",
    "#     for image in all_data[key]:\n",
    "#         #sort as train\n",
    "#         if random.random() < train_fraction:\n",
    "#             shutil.copy(image, f'./cell_images/train/{key}')\n",
    "#         else:\n",
    "#             shutil.copy(image, f'./cell_images/val/{key}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | 0/88 [36:49<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Uninfected       0.58      0.79      0.67      2807\n",
      " Parasitized       0.68      0.44      0.53      2805\n",
      "\n",
      "    accuracy                           0.61      5612\n",
      "   macro avg       0.63      0.61      0.60      5612\n",
      "weighted avg       0.63      0.61      0.60      5612\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2218  589]\n",
      " [1578 1227]]\n"
     ]
    }
   ],
   "source": [
    "# You can then proceed with evaluation, saving the model, etc.\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    progress_bar_eval = tqdm(all_dataloaders['val'], desc=\"Evaluating\", ncols=1000)\n",
    "    for inputs, labels in all_dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_labels, all_preds, target_names=[\"Uninfected\", \"Parasitized\"])\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'classifier3.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
